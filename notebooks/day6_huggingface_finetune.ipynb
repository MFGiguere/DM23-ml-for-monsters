{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fc350c",
   "metadata": {},
   "source": [
    "# Fine-tuning a HuggingFace model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef571f",
   "metadata": {},
   "source": [
    "## Code Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9d5d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    pipeline,\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8039c01",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "- A common use of LLMs is to leverage their **generalized** linguistic capacities by finetunint them for a **particular** task\n",
    "- For instance: We could take an LLM and train it to... \n",
    "    - classify text sequences\n",
    "    - classify tokens\n",
    "    - produce dialogue\n",
    "    - answer questions\n",
    "    - etc etc etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9c5e1",
   "metadata": {},
   "source": [
    "## Author Attribution\n",
    "\n",
    "- The task I want to train the model to perform on is to identify authors of text\n",
    "    - This is known as \"author attribution\"\n",
    "    - E.g. Italian Computer Scientists tried to identify Elena Ferrante by comparing her work with known Italian authors and journalists\n",
    "- We'll be using one of the few author attribution datasets on Huggingface \n",
    "    - Uses text from 13 journalists at the Guardian\n",
    "-  We can find the [data here](https://huggingface.co/datasets/guardian_authorship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ecc66",
   "metadata": {},
   "source": [
    "We load it by calling ```load_dataset```. The function needs the url of the dataset and a specification of which part of the data we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c161776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('guardian_authorship', 'cross_genre_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4854d0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 10,\n",
       " 'topic': 4,\n",
       " 'article': 'Chance Witness<br />by Matthew Parris<br />528pp, Viking, 18.99 I\\'ve known Matthew Parris pretty well for nearly 10 years, and he has always been kind and helpful and thoughtful, with only the occasional whiff of cattiness carried faintly on the breeze. He is also very kind about me in this alarmingly good book, so you might want to discount what follows. The cover shows Matthew with his hand over his mouth, as if he had just let slip a dangerous indiscretion. Yet I\\'ve read few autobiographies that are so carefully considered, so empty of anything glib or cheap. The only damaging material is about people who are already dead, or who are big enough to take it. (Among the many wonderful vignettes of Margaret Thatcher is one illustrating her reliance on the Sun, and in particular the two-bullet-point editorials that used to appear opposite page three. \"One day she plonked the paper down in front of the assembled male company, open at this spread, and said \\'what do you think of those two, eh?\\' No man present dared catch another\\'s eye.\") The book also made me laugh out loud several times. Parris is savage about the late and little lamented Dr Sir Alan Glyn, a Tory bore whom even the bores avoided. The descriptions of him eating langoustines, shell and all (\"I remember especially the feelers poking through his moustache and waving wildly as his yellowed teeth chomped the heads\"), and of the time the wardrobe fell over door side down with Dr Glyn inside are alone almost worth the price of the book. If the unexamined life is not worth living, then Matthew\\'s life has paid for itself several times. He learns from almost everything - his boyhood in Africa, his homosexuality, his work with Mrs Thatcher, his time as an MP, his disastrous stint on Weekend World, subsequent huge success as a journalist, and the inexplicable decision to spend four winter months on an almost uninhabited island near the Antarctic circle. There is the occasional infelicity, such as his description of the one time he had sex with a woman (\"it could have been a goat as far as I was concerned\") but far more perfectly expressed truths that illuminate and inform. My favourite is this: \"Being an MP feeds your vanity and starves your self-respect.\" This is a book full of wisdom and if we are invited along the way to share Matthew\\'s many triumphs, why not? Is he expected to leave them out? I had vaguely thought of writing my own autobiography at some stage, though my plan was to exclude myself almost entirely, since readers might be entertained by some of the events and people I have encountered, even if they had no interest in me. Having read this book I realise what a silly idea that is. Matthew has done much more than me, and thought about it all much more deeply. I was reminded of the Peanuts cartoon in which Linus and Charlie Brown are lying down looking at clouds. Charlie Brown asks Linus what he can see, and he replies (something like), \"I see a map of Prince Edward Island and a profile of the composer Aaron Copland. What do you see, Charlie Brown?\" \"I was going to say a horsey and a cat, but I don\\'t think I\\'ll bother now.\" Nor me.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0444a",
   "metadata": {},
   "source": [
    "There are some issues with the data, so I wrote a quick script to fix it. \n",
    "- Merge train, test and validate as pandas df\n",
    "- Create new Dataset\n",
    "- Do my own train_test_split\n",
    "\n",
    "Most often this is **not** the case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb57db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009935140609741211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Stringifying the column",
       "rate": null,
       "total": 444,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daebe6c4afbc413daadfffe8f476c5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010959625244140625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Casting to class labels",
       "rate": null,
       "total": 444,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae000508df342a89660a7d34c219b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fix_guardian_data(dataset):\n",
    "    # Add a label column to the data\n",
    "    dataset['train'] = dataset['train'].add_column(\"label\", dataset['train']['author'])\n",
    "    dataset['test'] = dataset['test'].add_column(\"label\", dataset['test']['author'])\n",
    "    dataset['validation'] = dataset['validation'].add_column(\"label\", dataset['validation']['author'])\n",
    "    \n",
    "    # We want to do our own test-train split\n",
    "    # To do this, I first make the data into one big dataframe\n",
    "    train_df = pd.DataFrame(dataset['train'])\n",
    "    test_df = pd.DataFrame(dataset['test'])\n",
    "    val_df = pd.DataFrame(dataset['validation'])\n",
    "    all_data = pd.concat([train_df, test_df, val_df])\n",
    "    \n",
    "    # Now I create a Huggingface dataset from that dataframe\n",
    "    dataset = Dataset.from_pandas(all_data)\n",
    "    \n",
    "    # I decide which column is the 'label' column\n",
    "    dataset = dataset.class_encode_column(\"label\")\n",
    "    \n",
    "    # Then I take the train_test_split. I want 20% of the data to be in the test set\n",
    "    dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\")\n",
    "    return dataset\n",
    "\n",
    "dataset = fix_guardian_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "981abe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['author', 'topic', 'article', 'label', '__index_level_0__'],\n",
       "        num_rows: 355\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['author', 'topic', 'article', 'label', '__index_level_0__'],\n",
       "        num_rows: 89\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e6702b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(dataset['train']['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bff51f1",
   "metadata": {},
   "source": [
    "Now we tokenize, as always for NLP. \n",
    "- Different LLM's use different tokenizers. \n",
    "- Like the model, our tokenizer needs to know where in the Huggingface Hub to look for specs to tokenize\n",
    "- We can use the  ```AutoTokenizer``` class instead of setting a particular tokenizer class\n",
    "\n",
    "We will be using DistilBERT, a smaller and more nimble version of BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b11a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d751c1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005986213684082031,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)okenizer_config.json",
       "rate": null,
       "total": 28,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf1b5ffc6b048358de07cec306d1082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\timax\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006983757019042969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)lve/main/config.json",
       "rate": null,
       "total": 483,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb8bdd67d7c4f4381baa1cc3cc6c5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007972955703735352,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)solve/main/vocab.txt",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9401fc7e80844b3a947abf534b93a57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007974863052368164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)/main/tokenizer.json",
       "rate": null,
       "total": 466062,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e998d3f59d840a783cfca73c8903203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00697636604309082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 355,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0ff3a5d4e147b7a6b25c666b1e767e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004982471466064453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 89,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d06af9d7c847d1b53e7157748caf05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"article\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564a2d0",
   "metadata": {},
   "source": [
    "Next we set our hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c022bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 10\n",
    "weight_decay = 0.01\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd64fbc",
   "metadata": {},
   "source": [
    "We feed most hyperparameters to the the [```TrainingArguments``` class](https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/trainer#transformers.TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "684a86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\", \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=weight_decay,\n",
    "    learning_rate=1e-5,\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c6bf5",
   "metadata": {},
   "source": [
    "Now we can specify our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "603627a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011960506439208984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading model.safetensors",
       "rate": null,
       "total": 267954768,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce47e72446648e2bbfefcc80bc7fa63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_type, num_labels=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254a6c6",
   "metadata": {},
   "source": [
    "When we train, we want to keep track of the model performance. For this we need to give the model a fucntion that takes in the eval and returns some sort of ... . For this we can use the ```evaluate``` library and write a function around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd056a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007967948913574219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading builder script",
       "rate": null,
       "total": 4203,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d99bfa5cfe426e95bc1f8ac136273f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b820e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7853ea",
   "metadata": {},
   "source": [
    "We can also create so called \"callbacks\". \n",
    "- These are objects that customize the training loop\n",
    "- Some of the deftault ones have [their own classes in HuggingFace](https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/callback)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cbb5df",
   "metadata": {},
   "source": [
    "In our case, we want the model to stop if it didn't improve during 3 sequential epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e95d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde2f0f",
   "metadata": {},
   "source": [
    "Finally, we create a [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer). \n",
    "- This is a class HuggingFace inherits from [```PyTorch Lightning```](https://lightning.ai/docs/pytorch/stable/common/trainer.html)\n",
    "- Used in many other libraries, like TorchGeo\n",
    "- Given an instance of a model class, this does the whole job of forward and backward passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f44a6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42),\n",
    "    eval_dataset=tokenized_datasets[\"test\"].shuffle(seed=42),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff999ee",
   "metadata": {},
   "source": [
    "Now we just run ```train()```, like with ```PyTorch```!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c999cb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006964921951293945,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 450,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc61cbd1c730441ba35e9282530e3592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\timax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\timax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1806\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m   1808\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1809\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1811\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1812\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1813\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1814\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1815\u001b[0m ):\n\u001b[0;32m   1816\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1817\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\timax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:2665\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2663\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m   2664\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2665\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[0;32m   2667\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32mc:\\Users\\timax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:1853\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1851\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1852\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1853\u001b[0m     loss\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\timax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\timax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb4a00",
   "metadata": {},
   "source": [
    "The model has finished training! \n",
    "- Now we can use it in a ```Huggingface``` pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ae339184",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a3616",
   "metadata": {},
   "source": [
    "The model outputs probabilities, no need to work with logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a66b1018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_3', 'score': 0.1491585373878479}]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(tokenized_datasets[\"test\"][50]['article'][:512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcf2fa",
   "metadata": {},
   "source": [
    "Now we'll compare the model predictions on the test set with our predictions on it.\n",
    "- We'll check if ```pred_lab == real_lab``` and count how many times it´s ```True```.\n",
    "    - This is our count for how many times we predicted correctly :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bb18a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for idx in range(len(tokenized_datasets[\"test\"]['author'])):\n",
    "    # We pull the predicted label from each prediction\n",
    "    # The model is only able to predict based on the 512 first tokens\n",
    "    pred_lab = pipe(tokenized_datasets[\"test\"][idx]['article'][:512])[0]['label']\n",
    "    \n",
    "    # The model outputs strings. \n",
    "    # We pull the number from it and turn it into an integere\n",
    "    pred_lab = int(re.findall(r'\\d+', pred_lab)[0])\n",
    "    \n",
    "    # We get the real label from the test data itself\n",
    "    real_lab = tokenized_datasets[\"test\"][idx]['label']\n",
    "    \n",
    "    # Now we compare and append to a list\n",
    "    correct.append(pred_lab == real_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9eb76751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 66, True: 23})"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d275e69",
   "metadata": {},
   "source": [
    "We could do more analysis. For example:\n",
    "- Which authors did the model struggle with?\n",
    "- Which did it predict confidently?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a774cc",
   "metadata": {},
   "source": [
    "Further work could include:\n",
    "- Pull out the model weights to see if there are specific words tha are important for predicting specific authors?\n",
    "- Test if we can deceive the model by performing style transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c8038a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
